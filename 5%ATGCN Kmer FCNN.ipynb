{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JfBsotlZyL3"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEYU05mOSWvs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn import metrics\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9gL-0P0Z1YA"
      },
      "source": [
        "# Installing UGent Panno font"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPbaFNecjvW6"
      },
      "source": [
        "Before running there are a few steps that need to be taken.\n",
        "\n",
        "Download this: https://www.ugent.be/intranet/nl/op-het-werk/communicatie/huisstijl-presentaties/huisstijl/panno-text.zip\n",
        "Unzip 'panno-text.zip'\n",
        "\n",
        "Open and unzip '150831-ugentpannotext-v300-truetype.zip'\n",
        "\n",
        "Upload the 'UGentPannoText-Normal' to this drive in the local directory!!!! (on the left bar, click the folder-icon, upload the 'UGentPannoText-Normal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG4RrDi9WMLr",
        "outputId": "af05616a-36c4-4097-873f-2bc87889c409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content/UGentPannoText-Normal.ttf', '/content/UGentPannoText-Medium.ttf', '/content/UGentPannoText-SemiLight.ttf', '/content/UGentPannoText-SemiBold.ttf']\n"
          ]
        }
      ],
      "source": [
        "#!mv UGentPannoText-Normal.ttf /usr/share/fonts/truetype/\n",
        "font_files = fm.findSystemFonts('.')\n",
        "\n",
        "for font_file in font_files:\n",
        "    fm.fontManager.addfont(font_file)\n",
        "print(font_files)\n",
        "plt.rc('font', family='UGent Panno Text')\n",
        "#path = '/usr/share/fonts/truetype/UGentPannoText-Normal.ttf'\n",
        "#fontprop = fm.FontProperties(fname=path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXi9gOWdZvtV"
      },
      "source": [
        "# Defining plot layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XW5lvPfWTH0"
      },
      "outputs": [],
      "source": [
        "plt.style.use('bmh')\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.labelsize'] = 10\n",
        "plt.rcParams['axes.labelweight'] = 'bold'\n",
        "plt.rcParams['axes.titlesize'] = 10\n",
        "plt.rcParams['xtick.labelsize'] = 8\n",
        "plt.rcParams['ytick.labelsize'] = 8\n",
        "plt.rcParams['legend.fontsize'] = 10\n",
        "plt.rcParams['figure.titlesize'] = 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGcAbKUEZsbY"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9WNN2PBWZoa"
      },
      "outputs": [],
      "source": [
        "def FCNK(kmer, tax, epochsize):\n",
        "    print(f'Initiating training, validation and testing on {tax} level with {kmer}.')\n",
        "\n",
        "    class mydataset(Dataset):\n",
        "        def __init__(self, x, y):\n",
        "            self.x = torch.tensor(x, dtype=torch.float32, device='cpu')\n",
        "            self.y = torch.tensor(y, dtype=torch.long, device='cpu')\n",
        "            self.length = self.x.shape[0]\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return self.x[idx], self.y[idx]\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.length\n",
        "\n",
        "    class Net(nn.Module):\n",
        "        def __init__(self, input_shape, output_shape, shape1, shape2):\n",
        "            super(Net, self).__init__()\n",
        "            self.fc1 = nn.Linear(input_shape, shape1)\n",
        "            self.fc2 = nn.Linear(shape1, shape2)\n",
        "            self.fcout = nn.Linear(shape2, output_shape)\n",
        "            self.relu = nn.ReLU()\n",
        "\n",
        "        def forward(self, x):\n",
        "            out = self.fc1(x)\n",
        "            out = self.relu(out)\n",
        "\n",
        "            out = self.fc2(out)\n",
        "            out = self.relu(out)\n",
        "\n",
        "            out = self.fcout(out)\n",
        "            return out\n",
        "\n",
        "    # Load the existed Training & Validation & Testing Dataset\n",
        "    base_path = '/content/drive/MyDrive/BachelorsProject/FinalModels/5AMBI/'\n",
        "    \n",
        "    # These files are all in my google drive\n",
        "    TrainX = np.load(f'{base_path}Train_X_{kmer}1A.npy')\n",
        "    TrainY = np.load(f'{base_path}Train_Y_{tax}1A.npy')\n",
        "    TestX = np.load(f'{base_path}Test_X_{kmer}1A.npy')\n",
        "    TestY = np.load(f'{base_path}Test_Y_{tax}1A.npy')\n",
        "    ValX = np.load(f'{base_path}Validation_X_{kmer}1A.npy')\n",
        "    ValY = np.load(f'{base_path}Validation_Y_{tax}1A.npy')\n",
        "    print('Training, test and validation datasets are loaded...')\n",
        "\n",
        "    batches = 100\n",
        "    trainset = mydataset(TrainX, TrainY)\n",
        "    valset = mydataset(ValX, ValY)\n",
        "    testset = mydataset(TestX, TestY)\n",
        "    trainloader = DataLoader(trainset, batch_size=batches, shuffle=True)\n",
        "    valloader = DataLoader(valset, batch_size=batches, shuffle=False)\n",
        "    testloader = DataLoader(testset, batch_size=batches, shuffle=False)\n",
        "    print('Loading trainset, trainloader, testset, testloader ...')\n",
        "\n",
        "    learning_rate = 0.001\n",
        "    epochs = epochsize\n",
        "    input_size = TrainX.shape[1]\n",
        "    size1 = TrainX.shape[1] * 3 // 4\n",
        "    size2 = TrainX.shape[1] * 1 // 4\n",
        "    output_size = len(np.unique(TrainY))\n",
        "    model = Net(input_shape=input_size, output_shape=output_size, shape1= size1, shape2= size2)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    print('Setting hyperparameters...')\n",
        "\n",
        "    training_losses = []\n",
        "    training_accuracies = []\n",
        "    validation_losses = []\n",
        "    validation_accuracies = []\n",
        "\n",
        "    print('Training model...')\n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        training_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for j, (x_train, y_train) in enumerate(trainloader):\n",
        "            # calculate output\n",
        "            output = model(x_train)\n",
        "\n",
        "            # calculate loss\n",
        "            loss = loss_fn(output, y_train)\n",
        "\n",
        "            # backprop\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate training loss and accuracy\n",
        "            training_loss += loss.item() * x_train.size(0)\n",
        "            output_tags = torch.argmax(output, dim=1)\n",
        "            targets = y_train\n",
        "            correct += (output_tags == targets).sum().item()\n",
        "            total += y_train.size(0)\n",
        "\n",
        "        # Print training statistics\n",
        "        epoch_loss = training_loss / len(trainloader.dataset)\n",
        "        epoch_acc = 100. * correct / total\n",
        "        print(f'Epoch [{epoch + 1}] Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.2f}%')\n",
        "\n",
        "        # Store the training loss and training accuracy\n",
        "        training_losses.append(epoch_loss)\n",
        "        training_accuracies.append(epoch_acc)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        validation_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for j, (x_val, y_val) in enumerate(valloader):\n",
        "                output = model(x_val)\n",
        "                loss = loss_fn(output, y_val)\n",
        "                # Calculate validation loss and accuracy\n",
        "                validation_loss += loss.item() * x_val.size(0)\n",
        "                output_tags = torch.argmax(output, dim=1)\n",
        "                targets = y_val\n",
        "                correct += (output_tags == targets).sum().item()\n",
        "                total += y_val.size(0)\n",
        "\n",
        "        # Print validation statistics\n",
        "        epoch_val_loss = validation_loss / len(valloader.dataset)\n",
        "        epoch_val_acc = 100. * correct / total\n",
        "        print(f'Epoch [{epoch + 1}] Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.2f}%')\n",
        "\n",
        "        # Store the validation loss and validation accuracy\n",
        "        validation_losses.append(epoch_val_loss)\n",
        "        validation_accuracies.append(epoch_val_acc)\n",
        "\n",
        "    # Testing\n",
        "    with torch.no_grad():\n",
        "        y_pred = []\n",
        "        y_true = []\n",
        "        # simple accuracy as above\n",
        "        for x_test, y_test in testloader:\n",
        "            test_output = model(x_test)\n",
        "            y_pred += torch.argmax(test_output, dim=1).tolist()\n",
        "            y_true += y_test.tolist()\n",
        "        report_dict = metrics.classification_report(y_true, y_pred, digits=3)\n",
        "        print(report_dict)\n",
        "\n",
        "\n",
        "    plt.plot(training_losses, label='Training', color='#1E64C8', linewidth=1)\n",
        "    plt.plot(validation_losses, label='Validation', color='black', linewidth=1)\n",
        "    plt.title(f'Training and Validation Loss of the FCN on {tax} level with {kmer}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss (in %)')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'FCNK{tax}{kmer}Loss1A.svg')\n",
        "    files.download(f'FCNK{tax}{kmer}Loss1A.svg') \n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(training_accuracies, label='Training', color='#1E64C8', linewidth=1)\n",
        "    plt.plot(validation_accuracies, label='Validation', color='black', linewidth=1)\n",
        "    plt.title(f'Training and Validation Accuracy of the FCN on {tax} level with {kmer}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (in %)')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'FCNK{tax}{kmer}Accuracy1A.svg')\n",
        "    files.download(f'FCNK{tax}{kmer}Accuracy1A.svg') \n",
        "    plt.show()\n",
        "    print(f'Training, validation and testing on {tax} level with {kmer} is completed.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "458JFrFcXWeU"
      },
      "source": [
        "# 3mer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC5SMyaIWwGK",
        "outputId": "dce8e826-6adc-40dd-b341-0005b0547082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initiating training, validation and testing on PHYLUM level with 3mer.\n",
            "Training, test and validation datasets are loaded...\n",
            "Loading trainset, trainloader, testset, testloader ...\n",
            "Setting hyperparameters...\n",
            "Training model...\n",
            "Epoch [1] Training Loss: 1.0205, Training Accuracy: 59.73%\n",
            "Epoch [1] Validation Loss: 0.7042, Validation Accuracy: 80.91%\n",
            "Epoch [2] Training Loss: 0.4261, Training Accuracy: 86.87%\n",
            "Epoch [2] Validation Loss: 0.2769, Validation Accuracy: 90.92%\n",
            "Epoch [3] Training Loss: 0.2348, Training Accuracy: 92.69%\n",
            "Epoch [3] Validation Loss: 0.1971, Validation Accuracy: 93.69%\n",
            "Epoch [4] Training Loss: 0.1883, Training Accuracy: 93.73%\n",
            "Epoch [4] Validation Loss: 0.1732, Validation Accuracy: 94.38%\n",
            "Epoch [5] Training Loss: 0.1656, Training Accuracy: 94.45%\n",
            "Epoch [5] Validation Loss: 0.1497, Validation Accuracy: 95.06%\n",
            "Epoch [6] Training Loss: 0.1484, Training Accuracy: 95.02%\n",
            "Epoch [6] Validation Loss: 0.1352, Validation Accuracy: 95.40%\n",
            "Epoch [7] Training Loss: 0.1358, Training Accuracy: 95.46%\n",
            "Epoch [7] Validation Loss: 0.1242, Validation Accuracy: 95.80%\n",
            "Epoch [8] Training Loss: 0.1245, Training Accuracy: 95.77%\n",
            "Epoch [8] Validation Loss: 0.1140, Validation Accuracy: 96.07%\n",
            "Epoch [9] Training Loss: 0.1149, Training Accuracy: 96.07%\n",
            "Epoch [9] Validation Loss: 0.1060, Validation Accuracy: 96.21%\n",
            "Epoch [10] Training Loss: 0.1062, Training Accuracy: 96.29%\n",
            "Epoch [10] Validation Loss: 0.0961, Validation Accuracy: 96.77%\n",
            "Epoch [11] Training Loss: 0.0976, Training Accuracy: 96.66%\n",
            "Epoch [11] Validation Loss: 0.0891, Validation Accuracy: 97.00%\n",
            "Epoch [12] Training Loss: 0.0918, Training Accuracy: 96.94%\n",
            "Epoch [12] Validation Loss: 0.0874, Validation Accuracy: 97.17%\n",
            "Epoch [13] Training Loss: 0.0862, Training Accuracy: 97.06%\n",
            "Epoch [13] Validation Loss: 0.0802, Validation Accuracy: 97.26%\n",
            "Epoch [14] Training Loss: 0.0817, Training Accuracy: 97.28%\n",
            "Epoch [14] Validation Loss: 0.0748, Validation Accuracy: 97.36%\n",
            "Epoch [15] Training Loss: 0.0773, Training Accuracy: 97.42%\n",
            "Epoch [15] Validation Loss: 0.0726, Validation Accuracy: 97.51%\n",
            "Epoch [16] Training Loss: 0.0740, Training Accuracy: 97.51%\n",
            "Epoch [16] Validation Loss: 0.0675, Validation Accuracy: 97.72%\n",
            "Epoch [17] Training Loss: 0.0709, Training Accuracy: 97.67%\n",
            "Epoch [17] Validation Loss: 0.0639, Validation Accuracy: 97.86%\n",
            "Epoch [18] Training Loss: 0.0671, Training Accuracy: 97.81%\n",
            "Epoch [18] Validation Loss: 0.0615, Validation Accuracy: 97.96%\n",
            "Epoch [19] Training Loss: 0.0644, Training Accuracy: 97.90%\n",
            "Epoch [19] Validation Loss: 0.0603, Validation Accuracy: 97.96%\n",
            "Epoch [20] Training Loss: 0.0625, Training Accuracy: 98.01%\n",
            "Epoch [20] Validation Loss: 0.0565, Validation Accuracy: 98.00%\n",
            "Epoch [21] Training Loss: 0.0606, Training Accuracy: 98.00%\n",
            "Epoch [21] Validation Loss: 0.0547, Validation Accuracy: 98.12%\n",
            "Epoch [22] Training Loss: 0.0576, Training Accuracy: 98.17%\n",
            "Epoch [22] Validation Loss: 0.0554, Validation Accuracy: 98.09%\n",
            "Epoch [23] Training Loss: 0.0563, Training Accuracy: 98.20%\n",
            "Epoch [23] Validation Loss: 0.0536, Validation Accuracy: 98.15%\n",
            "Epoch [24] Training Loss: 0.0542, Training Accuracy: 98.29%\n",
            "Epoch [24] Validation Loss: 0.0501, Validation Accuracy: 98.27%\n",
            "Epoch [25] Training Loss: 0.0526, Training Accuracy: 98.31%\n",
            "Epoch [25] Validation Loss: 0.0495, Validation Accuracy: 98.31%\n",
            "Epoch [26] Training Loss: 0.0507, Training Accuracy: 98.40%\n",
            "Epoch [26] Validation Loss: 0.0486, Validation Accuracy: 98.31%\n",
            "Epoch [27] Training Loss: 0.0497, Training Accuracy: 98.38%\n",
            "Epoch [27] Validation Loss: 0.0470, Validation Accuracy: 98.33%\n",
            "Epoch [28] Training Loss: 0.0482, Training Accuracy: 98.46%\n",
            "Epoch [28] Validation Loss: 0.0456, Validation Accuracy: 98.40%\n",
            "Epoch [29] Training Loss: 0.0466, Training Accuracy: 98.49%\n",
            "Epoch [29] Validation Loss: 0.0444, Validation Accuracy: 98.45%\n",
            "Epoch [30] Training Loss: 0.0452, Training Accuracy: 98.48%\n",
            "Epoch [30] Validation Loss: 0.0471, Validation Accuracy: 98.35%\n",
            "Epoch [31] Training Loss: 0.0442, Training Accuracy: 98.53%\n",
            "Epoch [31] Validation Loss: 0.0434, Validation Accuracy: 98.49%\n",
            "Epoch [32] Training Loss: 0.0432, Training Accuracy: 98.61%\n",
            "Epoch [32] Validation Loss: 0.0405, Validation Accuracy: 98.52%\n",
            "Epoch [33] Training Loss: 0.0413, Training Accuracy: 98.67%\n",
            "Epoch [33] Validation Loss: 0.0393, Validation Accuracy: 98.55%\n",
            "Epoch [34] Training Loss: 0.0411, Training Accuracy: 98.70%\n",
            "Epoch [34] Validation Loss: 0.0396, Validation Accuracy: 98.55%\n",
            "Epoch [35] Training Loss: 0.0398, Training Accuracy: 98.67%\n",
            "Epoch [35] Validation Loss: 0.0379, Validation Accuracy: 98.66%\n",
            "Epoch [36] Training Loss: 0.0382, Training Accuracy: 98.75%\n",
            "Epoch [36] Validation Loss: 0.0377, Validation Accuracy: 98.67%\n",
            "Epoch [37] Training Loss: 0.0378, Training Accuracy: 98.77%\n",
            "Epoch [37] Validation Loss: 0.0366, Validation Accuracy: 98.70%\n",
            "Epoch [38] Training Loss: 0.0370, Training Accuracy: 98.79%\n",
            "Epoch [38] Validation Loss: 0.0350, Validation Accuracy: 98.81%\n",
            "Epoch [39] Training Loss: 0.0358, Training Accuracy: 98.82%\n",
            "Epoch [39] Validation Loss: 0.0339, Validation Accuracy: 98.79%\n",
            "Epoch [40] Training Loss: 0.0347, Training Accuracy: 98.86%\n",
            "Epoch [40] Validation Loss: 0.0343, Validation Accuracy: 98.77%\n",
            "Epoch [41] Training Loss: 0.0342, Training Accuracy: 98.88%\n",
            "Epoch [41] Validation Loss: 0.0340, Validation Accuracy: 98.87%\n",
            "Epoch [42] Training Loss: 0.0330, Training Accuracy: 98.95%\n",
            "Epoch [42] Validation Loss: 0.0355, Validation Accuracy: 98.81%\n",
            "Epoch [43] Training Loss: 0.0326, Training Accuracy: 98.96%\n",
            "Epoch [43] Validation Loss: 0.0318, Validation Accuracy: 98.82%\n",
            "Epoch [44] Training Loss: 0.0319, Training Accuracy: 98.98%\n",
            "Epoch [44] Validation Loss: 0.0313, Validation Accuracy: 98.90%\n",
            "Epoch [45] Training Loss: 0.0315, Training Accuracy: 98.95%\n",
            "Epoch [45] Validation Loss: 0.0366, Validation Accuracy: 98.76%\n",
            "Epoch [46] Training Loss: 0.0308, Training Accuracy: 99.05%\n",
            "Epoch [46] Validation Loss: 0.0305, Validation Accuracy: 98.97%\n",
            "Epoch [47] Training Loss: 0.0300, Training Accuracy: 99.05%\n",
            "Epoch [47] Validation Loss: 0.0297, Validation Accuracy: 99.01%\n",
            "Epoch [48] Training Loss: 0.0297, Training Accuracy: 99.08%\n",
            "Epoch [48] Validation Loss: 0.0292, Validation Accuracy: 98.96%\n",
            "Epoch [49] Training Loss: 0.0290, Training Accuracy: 99.11%\n",
            "Epoch [49] Validation Loss: 0.0323, Validation Accuracy: 98.92%\n",
            "Epoch [50] Training Loss: 0.0289, Training Accuracy: 99.08%\n",
            "Epoch [50] Validation Loss: 0.0297, Validation Accuracy: 99.00%\n",
            "Epoch [51] Training Loss: 0.0279, Training Accuracy: 99.18%\n",
            "Epoch [51] Validation Loss: 0.0277, Validation Accuracy: 99.02%\n",
            "Epoch [52] Training Loss: 0.0276, Training Accuracy: 99.12%\n",
            "Epoch [52] Validation Loss: 0.0288, Validation Accuracy: 99.05%\n",
            "Epoch [53] Training Loss: 0.0277, Training Accuracy: 99.13%\n",
            "Epoch [53] Validation Loss: 0.0267, Validation Accuracy: 99.09%\n",
            "Epoch [54] Training Loss: 0.0269, Training Accuracy: 99.14%\n",
            "Epoch [54] Validation Loss: 0.0266, Validation Accuracy: 99.03%\n",
            "Epoch [55] Training Loss: 0.0260, Training Accuracy: 99.20%\n",
            "Epoch [55] Validation Loss: 0.0310, Validation Accuracy: 99.02%\n",
            "Epoch [56] Training Loss: 0.0259, Training Accuracy: 99.19%\n",
            "Epoch [56] Validation Loss: 0.0262, Validation Accuracy: 99.08%\n",
            "Epoch [57] Training Loss: 0.0257, Training Accuracy: 99.22%\n",
            "Epoch [57] Validation Loss: 0.0266, Validation Accuracy: 99.08%\n",
            "Epoch [58] Training Loss: 0.0253, Training Accuracy: 99.19%\n",
            "Epoch [58] Validation Loss: 0.0266, Validation Accuracy: 99.14%\n",
            "Epoch [59] Training Loss: 0.0246, Training Accuracy: 99.23%\n",
            "Epoch [59] Validation Loss: 0.0265, Validation Accuracy: 99.10%\n",
            "Epoch [60] Training Loss: 0.0245, Training Accuracy: 99.23%\n",
            "Epoch [60] Validation Loss: 0.0272, Validation Accuracy: 99.08%\n",
            "Epoch [61] Training Loss: 0.0243, Training Accuracy: 99.22%\n",
            "Epoch [61] Validation Loss: 0.0310, Validation Accuracy: 98.95%\n",
            "Epoch [62] Training Loss: 0.0241, Training Accuracy: 99.25%\n",
            "Epoch [62] Validation Loss: 0.0244, Validation Accuracy: 99.14%\n",
            "Epoch [63] Training Loss: 0.0237, Training Accuracy: 99.28%\n",
            "Epoch [63] Validation Loss: 0.0255, Validation Accuracy: 99.11%\n",
            "Epoch [64] Training Loss: 0.0235, Training Accuracy: 99.30%\n",
            "Epoch [64] Validation Loss: 0.0237, Validation Accuracy: 99.20%\n",
            "Epoch [65] Training Loss: 0.0232, Training Accuracy: 99.25%\n",
            "Epoch [65] Validation Loss: 0.0252, Validation Accuracy: 99.18%\n",
            "Epoch [66] Training Loss: 0.0228, Training Accuracy: 99.29%\n",
            "Epoch [66] Validation Loss: 0.0241, Validation Accuracy: 99.17%\n",
            "Epoch [67] Training Loss: 0.0222, Training Accuracy: 99.33%\n",
            "Epoch [67] Validation Loss: 0.0230, Validation Accuracy: 99.21%\n",
            "Epoch [68] Training Loss: 0.0220, Training Accuracy: 99.32%\n",
            "Epoch [68] Validation Loss: 0.0234, Validation Accuracy: 99.21%\n",
            "Epoch [69] Training Loss: 0.0219, Training Accuracy: 99.32%\n",
            "Epoch [69] Validation Loss: 0.0230, Validation Accuracy: 99.19%\n",
            "Epoch [70] Training Loss: 0.0219, Training Accuracy: 99.29%\n",
            "Epoch [70] Validation Loss: 0.0228, Validation Accuracy: 99.16%\n",
            "Epoch [71] Training Loss: 0.0213, Training Accuracy: 99.37%\n",
            "Epoch [71] Validation Loss: 0.0236, Validation Accuracy: 99.21%\n",
            "Epoch [72] Training Loss: 0.0211, Training Accuracy: 99.38%\n",
            "Epoch [72] Validation Loss: 0.0229, Validation Accuracy: 99.19%\n",
            "Epoch [73] Training Loss: 0.0211, Training Accuracy: 99.35%\n",
            "Epoch [73] Validation Loss: 0.0230, Validation Accuracy: 99.24%\n",
            "Epoch [74] Training Loss: 0.0209, Training Accuracy: 99.37%\n",
            "Epoch [74] Validation Loss: 0.0227, Validation Accuracy: 99.24%\n"
          ]
        }
      ],
      "source": [
        "FCNK('3mer', 'PHYLUM', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiiJ_Qw4XUtd"
      },
      "outputs": [],
      "source": [
        "FCNK('3mer', 'CLASS', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj4YLLJtXTx9"
      },
      "outputs": [],
      "source": [
        "FCNK('3mer', 'ORDER', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI6DTaSuXS4K"
      },
      "outputs": [],
      "source": [
        "FCNK('3mer', 'FAMILY', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bXle-l-XRrD"
      },
      "outputs": [],
      "source": [
        "FCNK('3mer', 'GENUS', 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC_APcLyXN6t"
      },
      "source": [
        "# 4mer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-gDT0i-XMvh"
      },
      "outputs": [],
      "source": [
        "FCNK('4mer', 'phylum', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrJBCEdGXL4z"
      },
      "outputs": [],
      "source": [
        "FCNK('4mer', 'class', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbvgA-sIXLay"
      },
      "outputs": [],
      "source": [
        "FCNK('4mer', 'order', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_tkCzNSXJ9r"
      },
      "outputs": [],
      "source": [
        "FCNK('4mer', 'family', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45c-8f6tXG5e"
      },
      "outputs": [],
      "source": [
        "FCNK('4mer', 'genus', 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfh1OSPvXFDC"
      },
      "source": [
        "# 5mer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFaJEdFyXD1J"
      },
      "outputs": [],
      "source": [
        "FCNK('5mer', 'phylum', 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D33GRo39XC3g"
      },
      "outputs": [],
      "source": [
        "FCNK('5mer', 'class', 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFll9cPZXBz3"
      },
      "outputs": [],
      "source": [
        "FCNK('5mer', 'order', 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXklnEqrXA8u"
      },
      "outputs": [],
      "source": [
        "FCNK('5mer', 'family', 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzYPxI7bW_7p"
      },
      "outputs": [],
      "source": [
        "FCNK('5mer', 'genus', 25)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "v9gL-0P0Z1YA",
        "NXi9gOWdZvtV",
        "JGcAbKUEZsbY",
        "458JFrFcXWeU",
        "CC_APcLyXN6t",
        "Pfh1OSPvXFDC"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}