{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn import metrics\n","\n","\n","class dataset(Dataset):\n","    def __init__(self, x, y):\n","        self.x = torch.tensor(x, dtype=torch.float32, device='cpu')\n","        self.y = torch.tensor(y, dtype=torch.long, device='cpu')\n","        self.length = self.x.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return self.x[idx], self.y[idx]\n","\n","    def __len__(self):\n","        return self.length\n","\n","\n","class Net(nn.Module):\n","    def __init__(self, input_shape, output_shape):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(input_shape, 126)\n","        self.fc2 = nn.Linear(126, 64)\n","        # self.fc2 = nn.Linear(100, 50)\n","        # self.fc3 = nn.Linear(128, 64)\n","        self.fcout = nn.Linear(64, output_shape)\n","\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.25)\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        #out = self.dropout(out)\n","\n","        out = self.fc2(out)\n","        out = self.relu(out)\n","        #out = self.dropout(out)\n","\n","        # out = self.fc3(out)\n","        # out = self.relu(out)\n","        # out = self.dropout(out)\n","\n","        out = self.fcout(out)\n","        #out = self.dropout(out)\n","        return out\n","\n","\n","# def compute_accuracy(output, targets):\n","#    predicted_labels = torch.argmax(output, dim=1)\n","#    targets = torch.argmax(targets, dim=1)  # get the index of the maximum value\n","#    num_correct = torch.sum(predicted_labels == targets).item()\n","#    accuracy = num_correct / len(targets)\n","#    return accuracy\n","\n","# def compute_accuracy(output, targets):\n","#    output_softmax = torch.log_softmax(output, dim=1)\n","#    _, output_tags = torch.max(output_softmax, dim=1)\n","#    _, targets = torch.max(targets, dim=1)\n","#    correct_pred = (output_tags == targets)\n","#    acc = correct_pred.sum() / len(correct_pred)\n","#    acc = torch.round(acc * 100)\n","#    return acc\n","\n","TrainX = np.load('Train_X_3mer.npy')\n","TrainY = np.load('Train_Y_PHYLUM.npy')\n","TestX = np.load('Test_X_3mer.npy')\n","TestY = np.load('Test_Y_PHYLUM.npy')\n","ValX = np.load('Validation_X_3mer.npy')\n","ValY = np.load('Validation_Y_PHYLUM.npy')\n","print('Training, test and validation datasets are loaded...')\n","\n","batches = 100\n","trainset = dataset(TrainX, TrainY)\n","valset = dataset(ValX, ValY)\n","testset = dataset(TestX, TestY)\n","trainloader = DataLoader(trainset, batch_size=batches, shuffle=True)\n","valloader = DataLoader(valset, batch_size=batches, shuffle=False)\n","testloader = DataLoader(testset, batch_size=batches, shuffle=False)\n","testloader2 = DataLoader(testset, shuffle=False)\n","print('Loading trainset, trainloader, testset, testloader ...')\n","\n","learning_rate = 0.001\n","epochs = 200\n","model = Net(input_shape=125, output_shape=16)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()\n","print('Setting hyperparameters...')\n","\n","training_losses = []\n","training_accuracies = []\n","validation_losses = []\n","validation_accuracies = []\n","\n","print('Training model...')\n","for epoch in range(epochs):\n","    # Training loop\n","    model.train()\n","    training_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for j, (x_train, y_train) in enumerate(trainloader):\n","        # calculate output\n","        output = model(x_train)\n","\n","        # calculate loss\n","        loss = loss_fn(output, y_train)\n","\n","        # backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Calculate training loss and accuracy\n","        training_loss += loss.item() * x_train.size(0)\n","        output_tags = torch.argmax(output, dim=1)\n","        targets = y_train\n","        correct += (output_tags == targets).sum().item()\n","        total += y_train.size(0)\n","\n","    # Print training statistics\n","    epoch_loss = training_loss / len(trainloader.dataset)\n","    epoch_acc = 100. * correct / total\n","    print(f'Epoch [{epoch + 1}] Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.2f}%')\n","\n","    # Store the training loss and training accuracy\n","    training_losses.append(epoch_loss)\n","    training_accuracies.append(epoch_acc)\n","\n","    # Validation loop\n","    model.eval()\n","    validation_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for j, (x_val, y_val) in enumerate(valloader):\n","            output = model(x_val)\n","            loss = loss_fn(output, y_val)\n","            # Calculate validation loss and accuracy\n","            validation_loss += loss.item() * x_val.size(0)\n","            output_tags = torch.argmax(output, dim=1)\n","            targets = y_val\n","            correct += (output_tags == targets).sum().item()\n","            total += y_val.size(0)\n","\n","    # Print validation statistics\n","    epoch_val_loss = validation_loss / len(valloader.dataset)\n","    epoch_val_acc = 100. * correct / total\n","    print(f'Epoch [{epoch + 1}] Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.2f}%')\n","\n","    # Store the validation loss and validation accuracy\n","    validation_losses.append(epoch_val_loss)\n","    validation_accuracies.append(epoch_val_acc)\n","\n","\n","# Testing\n","with torch.no_grad():\n","    test_accuracy = 0.0\n","    correct = 0\n","    total = 0\n","    y_pred = []\n","    y_true = []\n","    # simple accuracy as above\n","    for x_test, y_test in testloader:\n","        test_output = model(x_test)\n","        output_tags = torch.argmax(test_output, dim=1)\n","        targets = y_test\n","        correct += (output_tags == targets).sum().item()\n","        total += y_test.size(0)\n","        y_pred += torch.argmax(test_output, dim=1).tolist()\n","        y_true += y_test.tolist()\n","    print(metrics.classification_report(y_true, y_pred, digits=3))\n","    epoch_test_acc = 100. * correct / total\n","    print(f'Test accuracy: {epoch_test_acc:.2f}')\n","\n","\n","\n","# Project settings for plots\n","plt.style.use('bmh')\n","plt.rcParams['font.family'] = 'serif'\n","plt.rcParams['font.serif'] = 'UGent Panno Text'\n","plt.rcParams['font.monospace'] = 'UGent Panno Text'\n","plt.rcParams['font.size'] = 10\n","plt.rcParams['axes.labelsize'] = 10\n","plt.rcParams['axes.labelweight'] = 'bold'\n","plt.rcParams['axes.titlesize'] = 10\n","plt.rcParams['xtick.labelsize'] = 8\n","plt.rcParams['ytick.labelsize'] = 8\n","plt.rcParams['legend.fontsize'] = 10\n","plt.rcParams['figure.titlesize'] = 12\n","# Set an aspect ratio\n","\n","plt.plot(training_losses, label='Training', color='#1E64C8', linewidth=1)\n","plt.plot(validation_losses, label='Validation', color='black', linewidth=1)\n","plt.title('Training and Validation Loss with NAME on 3mers and phyla')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss (in %)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(training_accuracies, label='Training', color='#1E64C8', linewidth=1)\n","plt.plot(validation_accuracies, label='Validation', color='black', linewidth=1)\n","plt.title('Training and Validation Accuracy with NAME on 3mers and phyla')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (in %)')\n","plt.legend()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Running the code above on 3-mer and using phyla as labels, results in the following graphs and table:\n","![losstrainval](https://user-images.githubusercontent.com/127412115/236807579-5cb2d45e-cca4-4e84-872a-9e2875b08d78.png)\\\n","![acctrainval](https://user-images.githubusercontent.com/127412115/236807578-af234a32-f50c-42c2-9ed8-2dea7626d053.png)\n","\n","TEST RESULTS:\n","|     PHYLUM |  precision|    recall|  f1-score|   support|\n","|-----------:|:---------:|:--------:|:--------:|:---------|\n","|           0|      0.988|     0.996|     0.992|      8952|\n","|           1|      1.000|     1.000|     1.000|        11|\n","|           2|      0.997|     0.989|     0.993|     10231|\n","|           3|      0.714|     0.833|     0.769|         6|\n","|           4|      1.000|     1.000|     1.000|         5|\n","|           5|      0.827|     0.937|     0.878|       158|\n","|           6|      1.000|     0.818|     0.900|        11|\n","|           7|      1.000|     0.769|     0.870|        13|\n","|           8|      0.997|     0.994|     0.996|       689|\n","|           9|      0.892|     0.868|     0.880|        38|\n","|          10|      0.000|     0.000|     0.000|         3|\n","|          11|      0.986|     0.976|     0.981|       291|\n","|          12|      0.952|     0.959|     0.956|       292|\n","|          13|      1.000|     0.895|     0.944|        19|\n","|          14|      1.000|     1.000|     1.000|         2|\n","|          15|      0.800|     0.800|     0.800|        10|\n","|-----------:|:---------:|:--------:|:--------:|:---------|\n","|    accuracy|           |          |     0.990|     20731|\n","|   macro avg|      0.885|     0.865|     0.872|     20731|\n","|weighted avg|      0.990|     0.990|     0.990|     20731|\n","\n"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
