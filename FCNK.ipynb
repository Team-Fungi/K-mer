{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn import metrics\n","from google.colab import files\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","plt.style.use('bmh')\n","plt.rcParams['font.size'] = 10\n","plt.rcParams['axes.labelsize'] = 10\n","plt.rcParams['axes.labelweight'] = 'bold'\n","plt.rcParams['axes.titlesize'] = 10\n","plt.rcParams['xtick.labelsize'] = 8\n","plt.rcParams['ytick.labelsize'] = 8\n","plt.rcParams['legend.fontsize'] = 10\n","plt.rcParams['figure.titlesize'] = 12\n","\n","def FCNK(kmer, tax, epochsize):\n","    print(f'Initiating training, validation and testing on {tax} level with {kmer}.')\n","\n","    class mydataset(Dataset):\n","        def __init__(self, x, y):\n","            self.x = torch.tensor(x, dtype=torch.float32, device='cpu')\n","            self.y = torch.tensor(y, dtype=torch.long, device='cpu')\n","            self.length = self.x.shape[0]\n","\n","        def __getitem__(self, idx):\n","            return self.x[idx], self.y[idx]\n","\n","        def __len__(self):\n","            return self.length\n","\n","    class Net(nn.Module):\n","        def __init__(self, input_shape, output_shape, shape1, shape2):\n","            super(Net, self).__init__()\n","            self.fc1 = nn.Linear(input_shape, shape1)\n","            self.fc2 = nn.Linear(shape1, shape2)\n","            self.fcout = nn.Linear(shape2, output_shape)\n","            self.relu = nn.ReLU()\n","\n","        def forward(self, x):\n","            out = self.fc1(x)\n","            out = self.relu(out)\n","\n","            out = self.fc2(out)\n","            out = self.relu(out)\n","\n","            out = self.fcout(out)\n","            return out\n","\n","    # Load the existed Training & Validation & Testing Dataset\n","    base_path = '/content/drive/MyDrive/BachelorsProject/FinalModels/1AMBI/'\n","    \n","    # These files are all in my google drive\n","    TrainX = np.load(f'{base_path}Train_X_{kmer}1A.npy')\n","    TrainY = np.load(f'{base_path}Train_Y_{tax}1A.npy')\n","    TestX = np.load(f'{base_path}Test_X_{kmer}1A.npy')\n","    TestY = np.load(f'{base_path}Test_Y_{tax}1A.npy')\n","    ValX = np.load(f'{base_path}Validation_X_{kmer}1A.npy')\n","    ValY = np.load(f'{base_path}Validation_Y_{tax}1A.npy')\n","    print('Training, test and validation datasets are loaded...')\n","\n","    batches = 100\n","    trainset = mydataset(TrainX, TrainY)\n","    valset = mydataset(ValX, ValY)\n","    testset = mydataset(TestX, TestY)\n","    trainloader = DataLoader(trainset, batch_size=batches, shuffle=True)\n","    valloader = DataLoader(valset, batch_size=batches, shuffle=False)\n","    testloader = DataLoader(testset, batch_size=batches, shuffle=False)\n","    print('Loading trainset, trainloader, testset, testloader ...')\n","\n","    learning_rate = 0.001\n","    epochs = epochsize\n","    input_size = TrainX.shape[1]\n","    size1 = TrainX.shape[1] * 3 // 4\n","    size2 = TrainX.shape[1] * 1 // 4\n","    output_size = len(np.unique(TrainY))\n","    model = Net(input_shape=input_size, output_shape=output_size, shape1= size1, shape2= size2)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    loss_fn = nn.CrossEntropyLoss()\n","    print('Setting hyperparameters...')\n","\n","    training_losses = []\n","    training_accuracies = []\n","    validation_losses = []\n","    validation_accuracies = []\n","\n","    print('Training model...')\n","    for epoch in range(epochs):\n","        # Training loop\n","        model.train()\n","        training_loss = 0.0\n","        correct = 0\n","        total = 0\n","        for j, (x_train, y_train) in enumerate(trainloader):\n","            # calculate output\n","            output = model(x_train)\n","\n","            # calculate loss\n","            loss = loss_fn(output, y_train)\n","\n","            # backprop\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Calculate training loss and accuracy\n","            training_loss += loss.item() * x_train.size(0)\n","            output_tags = torch.argmax(output, dim=1)\n","            targets = y_train\n","            correct += (output_tags == targets).sum().item()\n","            total += y_train.size(0)\n","\n","        # Print training statistics\n","        epoch_loss = training_loss / len(trainloader.dataset)\n","        epoch_acc = 100. * correct / total\n","        print(f'Epoch [{epoch + 1}] Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.2f}%')\n","\n","        # Store the training loss and training accuracy\n","        training_losses.append(epoch_loss)\n","        training_accuracies.append(epoch_acc)\n","\n","        # Validation loop\n","        model.eval()\n","        validation_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        with torch.no_grad():\n","            for j, (x_val, y_val) in enumerate(valloader):\n","                output = model(x_val)\n","                loss = loss_fn(output, y_val)\n","                # Calculate validation loss and accuracy\n","                validation_loss += loss.item() * x_val.size(0)\n","                output_tags = torch.argmax(output, dim=1)\n","                targets = y_val\n","                correct += (output_tags == targets).sum().item()\n","                total += y_val.size(0)\n","\n","        # Print validation statistics\n","        epoch_val_loss = validation_loss / len(valloader.dataset)\n","        epoch_val_acc = 100. * correct / total\n","        print(f'Epoch [{epoch + 1}] Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.2f}%')\n","\n","        # Store the validation loss and validation accuracy\n","        validation_losses.append(epoch_val_loss)\n","        validation_accuracies.append(epoch_val_acc)\n","\n","    # Testing\n","    with torch.no_grad():\n","        y_pred = []\n","        y_true = []\n","        # simple accuracy as above\n","        for x_test, y_test in testloader:\n","            test_output = model(x_test)\n","            y_pred += torch.argmax(test_output, dim=1).tolist()\n","            y_true += y_test.tolist()\n","        report_dict = metrics.classification_report(y_true, y_pred, digits=3)\n","        print(report_dict)\n","\n","\n","    plt.plot(training_losses, label='Training', color='#1E64C8', linewidth=1)\n","    plt.plot(validation_losses, label='Validation', color='black', linewidth=1)\n","    plt.title(f'Training and Validation Loss of the FCN on {tax} level with {kmer}')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss (in %)')\n","    plt.legend()\n","    plt.savefig(f'FCNK{tax}{kmer}Loss1A.svg')\n","    files.download(f'FCNK{tax}{kmer}Loss1A.svg') \n","    plt.show()\n","\n","    plt.plot(training_accuracies, label='Training', color='#1E64C8', linewidth=1)\n","    plt.plot(validation_accuracies, label='Validation', color='black', linewidth=1)\n","    plt.title(f'Training and Validation Accuracy of the FCN on {tax} level with {kmer}')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (in %)')\n","    plt.legend()\n","    plt.savefig(f'FCNK{tax}{kmer}Accuracy1A.svg')\n","    files.download(f'FCNK{tax}{kmer}Accuracy1A.svg') \n","    plt.show()\n","    print(f'Training, validation and testing on {tax} level with {kmer} is completed.')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We then run the model on all taxonomic levels with 3mer, 4mer and 5mer."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# 3 mer - 200 epoch\n","FCNK('3mer', 'phylum', 200)\n","FCNK('3mer', 'class', 200)\n","FCNK('3mer', 'order', 200)\n","FCNK('3mer', 'family', 200)\n","FCNK('3mer', 'genus', 200)\n","\n","# 4 mer - 100 epoch\n","FCNK('4mer', 'phylum', 100)\n","FCNK('4mer', 'class', 100)\n","FCNK('4mer', 'order', 100)\n","FCNK('4mer', 'family', 100)\n","FCNK('4mer', 'genus', 100)\n","\n","# 5 mer - 50 epoch\n","FCNK('5mer', 'phylum', 25)\n","FCNK('5mer', 'class', 25)\n","FCNK('5mer', 'order', 25)\n","FCNK('5mer', 'family', 25)\n","FCNK('5mer', 'genus', 25)\n"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
